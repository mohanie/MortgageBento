{"nbformat_minor": 1, "cells": [{"source": "<table style=\"border: none\" align=\"left\">\n   <tr style=\"border: none\">\n      <th style=\"border: none\"><font face=\"verdana\" size=\"5\" color=\"black\"><b>Mortgage Complaints using Watson Machine Learning</b></font></th>\n      <th style=\"border: none\"><img src=\"https://github.com/pmservice/customer-satisfaction-prediction/blob/master/app/static/images/ml_icon_gray.png?raw=true\" alt=\"Watson Machine Learning icon\" height=\"40\" width=\"40\"></th>\n   </tr> \n   <tr style=\"border: none\">\n       <td style=\"border: none\"><img src=\"https://github.com/pmservice/wml-sample-models/raw/master/spark/drug-selection/images/learning_banner-05.png\" width=\"600\" alt=\"Icon\"></td>\n   </tr>\n</table>", "cell_type": "markdown", "metadata": {}}, {"source": "This notebook contains steps and code to train a Spark model with a Naive Bayes Multi-Class Text Classification. This notebook introduces commands for getting data, model persistance to Watson Machine Learning repository, model deployment, and scoring.\n\nThis notebook uses Python 3.5 and Apache Spark 2.1.\n\nYou will use the data. MORTGAGE_ISSUES_TRAINING.csv and MORTGAGE_ISSUES_TEST.csv files, which contains anonymous information about Mortgage Complaints got from the <a href=\"https://www.consumerfinance.gov/data-research/consumer-complaints/search/?from=0&searchField=all&searchText=&size=25&sort=created_date_desc\">Consumer Complaint Database</a>\n\n## Learning goals\n\nThis notebook teaches you how to:\n-  Publish a sample model in the Watson Machine Learning (WML) repository\n\nYou will also learn how to use the WML API to:\n-  Deploy a model for online scoring \n\n\n## Contents\n\nThis notebook contains the following parts:\n\n1.\t[Set up the environment](#setup)\n2.\t[Create spark ml model](#model)\n3.\t[Store the model](#store)\n4.\t[Deploy & score](#score)", "cell_type": "markdown", "metadata": {}}, {"source": "<a id=\"setup\"></a>\n## 1. Set up the environment\n\nBefore you use the sample code in this notebook, you must perform the following setup tasks:\n\n- Create a [Watson Machine Learning (WML) Service](https://console.ng.bluemix.net/catalog/services/ibm-watson-machine-learning/) instance (a free plan is offered and information about how to create the instance is [here](https://dataplatform.ibm.com/docs/content/analyze-data/wml-setup.html))\n- Create a [Spark Service](https://console.ng.bluemix.net/catalog/services/spark/) instance (an entry plan is offered). [Associated](https://dataplatform.cloud.ibm.com/docs/content/getting-started/assoc-services.html?audience=wdp&linkInPage=true) the Spark service with your Watson Studio project.\n- Create a [Db2 Warehouse on Cloud Service](https://console.bluemix.net/catalog/services/db2-warehouse-on-cloud/) instance (an entry plan is offered).\n  + Download [MORTGAGE_ISSUES_TRAINING.csv](https://github.com/mohanie/MortgageBento/raw/master/data/MORTGAGE_ISSUES_TRAINING.csv) and [MORTGAGE_ISSUES_TEST.csv](https://github.com/mohanie/MortgageBento/raw/master/data/MORTGAGE_ISSUES_TEST.csv) file from git repository.\n  + Click **Open the console** to get started with **Db2 Warehouse on Cloud** icon.\n  + Select the **Load Data** and **Desktop** load type.\n  + **Drag and drop** previously downloaded file and press **Next**.\n  + Select **Schema** to import data and click **New Table**. \n  + Write the name **MORTGAGE_ISSUES_TRAINING** for **new table** than click **Next** to finish data import.\n  + Use `,` as **field separator**.\n  + Click **Next** to create a table with the uploaded data.\n  + Repeat steps to load **MORTGAGE_ISSUES_TEST.csv** file", "cell_type": "markdown", "metadata": {}}, {"source": "<a id=\"model\"></a>\n## 2. Create the spark machine learning model", "cell_type": "markdown", "metadata": {}}, {"source": "In this section you will learn how to prepare data, create an Apache Spark machine learning pipeline, and train a model.\n\n- [2.1 Load the training data from Db2 Warehouse on Cloud](#load)\n- [2.2 Explore the data](#explore)\n- [2.3 Create the pipeline](#pipe)\n- [2.4 Train the model](#train)\n- [2.5 Test the accuracy](#accuracy)", "cell_type": "markdown", "metadata": {}}, {"source": "### 2.1 Load the training data from Db2 Warehouse on Cloud<a id=\"load\"></a>", "cell_type": "markdown", "metadata": {}}, {"source": "Run the following cell to the load the **MORTGAGE_ISSUES_TRAINING** and **MORTGAGE_ISSUES_TEST** table content into the Spark DataFrame.\n\nEnter your authentication data as required. \n\n**Tip:** The authentication information can be found under the **Service Credentials**  tab of Db2 Warehouse on Cloud service instance created in IBM Cloud. Click **New credential** to create credentials if you do not have any.", "cell_type": "markdown", "metadata": {}}, {"source": "from ingest.Connectors import Connectors\nfrom pyspark.sql import SQLContext\nsqlContext = SQLContext(sc)\n\ndashDBloadTraining = {Connectors.DASHDB.HOST              : 'dashdb-entry-yp-dal10-01.services.dal.bluemix.net',\n                      Connectors.DASHDB.DATABASE          : 'BLUDB',\n                      Connectors.DASHDB.USERNAME          : '***',\n                      Connectors.DASHDB.PASSWORD          : '***',\n                      Connectors.DASHDB.SOURCE_TABLE_NAME : 'MORTGAGE_ISSUES_TRAINING'}\n\ndashDBloadTest = { Connectors.DASHDB.HOST              : 'dashdb-entry-yp-dal09-10.services.dal.bluemix.net',\n                      Connectors.DASHDB.DATABASE          : 'BLUDB',\n                      Connectors.DASHDB.USERNAME          : '***',\n                      Connectors.DASHDB.PASSWORD          : '***',\n                      Connectors.DASHDB.SOURCE_TABLE_NAME : 'MORTGAGE_ISSUES_TEST'}\n\nmortgage_training_data = sqlContext.read.format(\"com.ibm.spark.discover\").options(**dashDBloadTraining).load()\nmortgage_test_data = sqlContext.read.format(\"com.ibm.spark.discover\").options(**dashDBloadTest).load()", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 1}, {"source": "<a id=\"explore\"></a>\n### 2.2 Explore the data", "cell_type": "markdown", "metadata": {}}, {"source": "In this subsection you will explore the data.\n- Show MORTGAGE_ISSUES_TRAIN Spark DataFrame schema and total rows.\n- Show MORTGAGE_ISSUES_TEST Spark DataFrame schema and total rows.\n- List most complaints.\n- List the complaints categories.", "cell_type": "markdown", "metadata": {}}, {"source": "print(\"MORTGAGE_ISSUES_TRAIN\")\nmortgage_training_data.printSchema()\nmortgage_training_data.show()\nprint(\"Total Rows : \"+str(mortgage_training_data.count())+\"\\n\")\n\nprint(\"MORTGAGE_ISSUES_TEST\")\nmortgage_test_data.printSchema()\nmortgage_test_data.show()\nprint(\"Total Rows : \"+str(mortgage_test_data.count())+\"\\n\")\n\nprint(\"The most complaints\")\nfrom pyspark.sql.functions import col\nmortgage_training_data.groupBy(\"CONSUMER_COMPLAINT_NARRATIVE\") \\\n        .count() \\\n        .orderBy(col(\"count\").desc()) \\\n        .show()\n\nprint(\"Complaints categories.\")\nmortgage_training_data.select(\"ISSUE\").distinct().show()", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "MORTGAGE_ISSUES_TRAIN\nroot\n |-- CONSUMER_COMPLAINT_NARRATIVE: string (nullable = true)\n |-- ISSUE: string (nullable = true)\n\n+----------------------------+--------------------+\n|CONSUMER_COMPLAINT_NARRATIVE|               ISSUE|\n+----------------------------+--------------------+\n|        I AM ATTEMPTING T...|Loan modification...|\n|        On XX/XX/2016 I c...|Loan modification...|\n|        SHERIFF SALE TODA...|Loan modification...|\n|        I am a Mortgage b...|Loan servicing pa...|\n|        I recently sold m...|Settlement proces...|\n|        SLS had requested...|Settlement proces...|\n|        I refinanced my m...|Settlement proces...|\n|        On XX/XX/2017 - X...|Settlement proces...|\n|        post closing the ...|Settlement proces...|\n|        I contacted Resid...|Settlement proces...|\n|        On  XXXX    XXXX ...|Settlement proces...|\n|        Ditech collects e...|Loan servicing pa...|\n|        I recently purcha...|Loan servicing pa...|\n|        I have a mortgage...|Loan servicing pa...|\n|        CitiMortgage said...|Loan servicing pa...|\n|        Shellpoint Mortga...|Loan servicing pa...|\n|        I opened a new mo...|Loan servicing pa...|\n|        Back in XXXX my m...|Loan servicing pa...|\n|        XXXX XXXX XXXX tr...|Loan servicing pa...|\n|        I am in the proce...|Loan servicing pa...|\n+----------------------------+--------------------+\nonly showing top 20 rows\n\nTotal Rows : 15096\n\nMORTGAGE_ISSUES_TEST\nroot\n |-- CONSUMER_COMPLAINT_NARRATIVE: string (nullable = true)\n |-- ISSUE: string (nullable = true)\n\n+----------------------------+--------------------+\n|CONSUMER_COMPLAINT_NARRATIVE|               ISSUE|\n+----------------------------+--------------------+\n|        I was preapproved...|Application origi...|\n|        I submitted an on...|Application origi...|\n|        I financed my hou...|Application origi...|\n|        I contacted Ameri...|Application origi...|\n|        In XXXX  2016  I ...|Application origi...|\n|        We have been dela...|Application origi...|\n|        Wells Fargo enter...|Application origi...|\n|        XX/XX/XXXX I was ...|Application origi...|\n|        I am in the proce...|Application origi...|\n|        We are in despera...|Settlement proces...|\n|        I was contacted b...|Settlement proces...|\n|        This company lied...|Settlement proces...|\n|        Suntrust was orde...|Settlement proces...|\n|        On or around XX/X...|Settlement proces...|\n|        My original mortg...|Settlement proces...|\n|        On XXXX XXXX  201...|Settlement proces...|\n|        In an effort to c...|Settlement proces...|\n|        I bought a house ...|Settlement proces...|\n|        XXXX XXXX XXXX  2...|Settlement proces...|\n|        We sold our home ...|Settlement proces...|\n+----------------------------+--------------------+\nonly showing top 20 rows\n\nTotal Rows : 2400\n\nThe most complaints\n+----------------------------+-----+\n|CONSUMER_COMPLAINT_NARRATIVE|count|\n+----------------------------+-----+\n|        Had several mortg...|    3|\n|        The response is f...|    3|\n|        I tried to submit...|    2|\n|        Mortgage Payment ...|    2|\n|        FORECLOSURE SALE ...|    2|\n|        I have had a very...|    2|\n|        I have been payin...|    2|\n|        Plaintiffs  at al...|    2|\n|        I fell behind on ...|    1|\n|        I signed up for a...|    1|\n|        My mortgage is fi...|    1|\n|        My finance compan...|    1|\n|        my mother got beh...|    1|\n|        My complaint is a...|    1|\n|        My XXXX Mortgage ...|    1|\n|        I applied for a m...|    1|\n|        Dear CFPB- I am w...|    1|\n|        I refinance my ho...|    1|\n|        Nationstar Mortga...|    1|\n|        During the proces...|    1|\n+----------------------------+-----+\nonly showing top 20 rows\n\nComplaints categories.\n+--------------------+\n|               ISSUE|\n+--------------------+\n|Loan modification...|\n|Loan servicing pa...|\n|Settlement proces...|\n|Credit decision U...|\n|Struggling to pay...|\n|Trouble during pa...|\n|Application origi...|\n|Closing on a mort...|\n+--------------------+\n\n"}], "execution_count": 2}, {"source": "<a id=\"pipe\"></a>\n### 2.3 Create the pipeline", "cell_type": "markdown", "metadata": {}}, {"source": "- regexTokenizer: Tokenization the CONSUMER_COMPLAINT_NARRATIVE text with Regular Expression\n- stopwordsRemover: A list of Stop Words to remove\n- countVectors: Convert the output of the Tokenization to vectors of token counts.", "cell_type": "markdown", "metadata": {}}, {"source": "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer,HashingTF, IDF\nfrom pyspark.ml.classification import LogisticRegression\n\nregexTokenizer = RegexTokenizer(inputCol=\"CONSUMER_COMPLAINT_NARRATIVE\", outputCol=\"words\")\n\nadd_stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\",\"XXXX\", \"XX\", \"My\",\"I\",\"To\",\"Hello\" ]\nstopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\").setStopWords(add_stopwords)\n\ncountVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=10000, minDF=5)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 3}, {"source": "- StringIndexer encodes a string column of labels to a column of label indices. The indices are in [0, numLabels), ordered by label frequencies, so the most frequent label gets index 0.\n- IndexToString convert Encoded Issue Types back to String.", "cell_type": "markdown", "metadata": {}}, {"source": "from pyspark.ml.feature import StringIndexer, IndexToString\n\nlabel_stringIdx = StringIndexer(inputCol = \"ISSUE\", outputCol = \"label\").fit(mortgage_training_data)\n\nlabel_converter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=label_stringIdx.labels)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 4}, {"source": "- Define a Naive Bayes multiclass classification.\n- Create the Spark pipeline.", "cell_type": "markdown", "metadata": {}}, {"source": "from pyspark.ml import Pipeline\nfrom pyspark.ml.classification import NaiveBayes\n\nNB = NaiveBayes(smoothing=1)\n\nSparkPipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors, label_stringIdx,NB,label_converter])", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 5}, {"source": "<a id=\"train\"></a>\n### 2.4 Train the model", "cell_type": "markdown", "metadata": {}}, {"source": "Now, you can train your Naive Bayes model by using the previously defined pipeline and train data.", "cell_type": "markdown", "metadata": {}}, {"source": "NBmodel = SparkPipeline.fit(mortgage_training_data)\nPredictedLabel = NBmodel.transform(mortgage_training_data)\nPredictedLabel.select('CONSUMER_COMPLAINT_NARRATIVE', 'ISSUE', 'prediction','predictedLabel').show(5)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "+----------------------------+--------------------+----------+--------------------+\n|CONSUMER_COMPLAINT_NARRATIVE|               ISSUE|prediction|      predictedLabel|\n+----------------------------+--------------------+----------+--------------------+\n|        filed s previous ...|Credit decision U...|       0.0|Loan servicing pa...|\n|        This is a complai...|Credit decision U...|       7.0|Credit decision U...|\n|        I obtained a home...|Credit decision U...|       0.0|Loan servicing pa...|\n|        I purchased a hom...|Credit decision U...|       1.0|Loan modification...|\n|        It has been 10 we...|Credit decision U...|       7.0|Credit decision U...|\n+----------------------------+--------------------+----------+--------------------+\nonly showing top 5 rows\n\n"}], "execution_count": 6}, {"source": "<a id=\"accuracy\"></a>\n### 2.5 Test the accuracy", "cell_type": "markdown", "metadata": {}}, {"source": "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\npredictions = NBmodel.transform(mortgage_test_data)\npredictions.filter(predictions['prediction'] == 0) \\\n    .select(\"CONSUMER_COMPLAINT_NARRATIVE\",\"ISSUE\",\"probability\",\"label\",\"prediction\",\"predictedLabel\") \\\n    .orderBy(\"probability\", ascending=False) \\\n    .show(n = 10, truncate = 30)\n\nevaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = evaluator.evaluate(predictions)\nprint(\"Accuracy = %g\" % accuracy)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "+------------------------------+------------------------------+------------------------------+-----+----------+------------------------------+\n|  CONSUMER_COMPLAINT_NARRATIVE|                         ISSUE|                   probability|label|prediction|                predictedLabel|\n+------------------------------+------------------------------+------------------------------+-----+----------+------------------------------+\n|In XXXX 2015 we obtained a ...|Loan servicing payments esc...|[1.0,2.4174454747610357E-28...|  0.0|       0.0|Loan servicing payments esc...|\n|SENECA MORTGAGE SERVICING X...|Loan servicing payments esc...|[1.0,1.614037692951306E-41,...|  0.0|       0.0|Loan servicing payments esc...|\n|We paid our mortgage to Car...|Loan servicing payments esc...|[1.0,4.492948716573328E-65,...|  0.0|       0.0|Loan servicing payments esc...|\n|My previous lender sold my ...|    Struggling to pay mortgage|[0.9999999999999987,3.51717...|  3.0|       0.0|Loan servicing payments esc...|\n|On XXXX XXXX  2016  I made ...|Loan servicing payments esc...|[0.9999999999999767,1.76166...|  0.0|       0.0|Loan servicing payments esc...|\n|Our original Mortgage was t...|Loan servicing payments esc...|[0.9999999999994842,1.10837...|  0.0|       0.0|Loan servicing payments esc...|\n|my mortgage company Vanderb...|Loan servicing payments esc...|[0.9999999999961873,2.63614...|  0.0|       0.0|Loan servicing payments esc...|\n|Hello  I have serveral prob...|Loan servicing payments esc...|[0.9999999999868976,1.53820...|  0.0|       0.0|Loan servicing payments esc...|\n|Planet home lending took ov...|Loan servicing payments esc...|[0.9999999999730558,2.13689...|  0.0|       0.0|Loan servicing payments esc...|\n|Last year my mortgage was s...|Loan servicing payments esc...|[0.9999999999635047,1.05776...|  0.0|       0.0|Loan servicing payments esc...|\n+------------------------------+------------------------------+------------------------------+-----+----------+------------------------------+\nonly showing top 10 rows\n\nAccuracy = 0.614167\n"}], "execution_count": 7}, {"source": "<a id=\"store\"></a>\n## 3. Store the model", "cell_type": "markdown", "metadata": {}}, {"source": "In this section you will learn how to store sample model in Watson Machine Learning repository by using repository client.", "cell_type": "markdown", "metadata": {}}, {"source": "First, install and import the client library.", "cell_type": "markdown", "metadata": {}}, {"source": "!rm -rf $PIP_BUILD\n!pip install --upgrade watson-machine-learning-client==1.0.260", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Requirement already up-to-date: watson-machine-learning-client==1.0.260 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s0d3-9feb51e0b4d68d-c1ce9e972176/.local/lib/python3.5/site-packages (1.0.260)\nRequirement not upgraded as not directly required: tqdm in /usr/local/src/conda3_runtime.v47/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages (from watson-machine-learning-client==1.0.260) (4.19.4)\nRequirement not upgraded as not directly required: tabulate in /usr/local/src/conda3_runtime.v47/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages (from watson-machine-learning-client==1.0.260) (0.8.2)\nRequirement not upgraded as not directly required: urllib3 in /usr/local/src/conda3_runtime.v47/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages (from watson-machine-learning-client==1.0.260) (1.22)\nRequirement not upgraded as not directly required: certifi in /usr/local/src/conda3_runtime.v47/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages (from watson-machine-learning-client==1.0.260) (2018.10.15)\nRequirement not upgraded as not directly required: pandas in /usr/local/src/conda3_runtime.v47/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages (from watson-machine-learning-client==1.0.260) (0.21.0)\nRequirement not upgraded as not directly required: lomond in /usr/local/src/conda3_runtime.v47/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages (from watson-machine-learning-client==1.0.260) (0.1.12)\nRequirement not upgraded as not directly required: ibm-cos-sdk in /usr/local/src/conda3_runtime.v47/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages (from watson-machine-learning-client==1.0.260) (2.0.1)\nRequirement not upgraded as not directly required: requests in /usr/local/src/conda3_runtime.v47/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages (from watson-machine-learning-client==1.0.260) (2.18.4)\nRequirement not upgraded as not directly required: python-dateutil>=2 in /usr/local/src/conda3_runtime.v47/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages (from pandas->watson-machine-learning-client==1.0.260) (2.6.1)\nRequirement not upgraded as not directly required: pytz>=2011k in /usr/local/src/conda3_runtime.v47/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages (from pandas->watson-machine-learning-client==1.0.260) (2018.4)\nRequirement not upgraded as not directly required: numpy>=1.9.0 in /usr/local/src/conda3_runtime.v47/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages (from pandas->watson-machine-learning-client==1.0.260) (1.13.3)\nRequirement not upgraded as not directly required: six>=1.10.0 in /usr/local/src/conda3_runtime.v47/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages (from lomond->watson-machine-learning-client==1.0.260) (1.11.0)\nRequirement not upgraded as not directly required: ibm-cos-sdk-core==2.*,>=2.0.0 in /usr/local/src/conda3_runtime.v47/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages (from ibm-cos-sdk->watson-machine-learning-client==1.0.260) (2.0.1)\nRequirement not upgraded as not directly required: ibm-cos-sdk-s3transfer==2.*,>=2.0.0 in /usr/local/src/conda3_runtime.v47/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages (from ibm-cos-sdk->watson-machine-learning-client==1.0.260) (2.0.1)\nRequirement not upgraded as not directly required: chardet<3.1.0,>=3.0.2 in /usr/local/src/conda3_runtime.v47/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages (from requests->watson-machine-learning-client==1.0.260) (3.0.4)\nRequirement not upgraded as not directly required: idna<2.7,>=2.5 in /usr/local/src/conda3_runtime.v47/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages (from requests->watson-machine-learning-client==1.0.260) (2.6)\nRequirement not upgraded as not directly required: docutils>=0.10 in /usr/local/src/conda3_runtime.v47/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages (from ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk->watson-machine-learning-client==1.0.260) (0.14)\nRequirement not upgraded as not directly required: jmespath<1.0.0,>=0.7.1 in /usr/local/src/conda3_runtime.v47/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages (from ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk->watson-machine-learning-client==1.0.260) (0.9.3)\n\u001b[31mnotebook 5.0.0 requires nbconvert, which is not installed.\u001b[0m\n\u001b[31mipywidgets 6.0.0 requires widgetsnbextension~=2.0.0, which is not installed.\u001b[0m\n\u001b[31mtensorflow 1.3.0 requires tensorflow-tensorboard<0.2.0,>=0.1.0, which is not installed.\u001b[0m\n"}], "execution_count": 8}, {"source": "**Note**: Apache Spark 2.1 is required.", "cell_type": "markdown", "metadata": {}}, {"source": "from watson_machine_learning_client import WatsonMachineLearningAPIClient", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stderr", "text": "2018-11-26 10:28:18,609 - watson_machine_learning_client.metanames - WARNING - 'AUTHOR_EMAIL' meta prop is deprecated. It will be ignored.\n"}], "execution_count": 9}, {"source": "Authenticate to the Watson Machine Learning service on IBM Cloud.\n\n**Tip**: Authentication information (your credentials) can be found in the <a href=\"https://console.bluemix.net/docs/services/service_credentials.html#service_credentials\" target=\"_blank\" rel=\"noopener no referrer\">Service Credentials</a> tab of the service instance that you created on IBM Cloud. \n\nIf you cannot see the **instance_id** field in **Service Credentials**, click **New credential (+)** to generate new authentication information. \n\n**Action**: Enter your Watson Machine Learning service instance credentials here.", "cell_type": "markdown", "metadata": {}}, {"source": "wml_credentials = {\n  \"apikey\": \"***\",\n  \"iam_apikey_description\": \"***\",\n  \"iam_apikey_name\": \"***\",\n  \"iam_role_crn\": \"***\",\n  \"iam_serviceid_crn\": \"***\",\n  \"instance_id\": \"***\",\n  \"password\": \"***\",\n  \"url\": \"***\",\n  \"username\": \"***\"\n}", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 10}, {"source": "Create the WatsonMachineLearningAPIClient.", "cell_type": "markdown", "metadata": {}}, {"source": "client = WatsonMachineLearningAPIClient(wml_credentials)\nclient.version", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "'1.0.260'"}, "execution_count": 11}], "execution_count": 11}, {"source": "#### Prepare the metadata", "cell_type": "markdown", "metadata": {}}, {"source": "**Tip**: If the accuracy value falls below the threshold value, retraining action is required.", "cell_type": "markdown", "metadata": {}}, {"source": "Prepare the additional information to be saved as model's metadata:\n* TRAINING_DATA_REFERENCE\n* OUTPUT_DATA_SCHEMA\n* EVALUATION_METHOD: **multiclass**\n* EVALUATION_METRICS name: **accuracy** (metric name used to evaluate the model)\n* EVALUATION_METRICS value: **0.61** (accuracy value calculated few steps above)\n* EVALUATION_METRICS threshold: **0.6** (if the accuracy after evaluation using feedback data is below this threshold auto-retraining is triggered)", "cell_type": "markdown", "metadata": {}}, {"source": "**Tip**: All required fields can be found on Service Credentials tab of Db2 Warehouse on Cloud service instance created in IBM Cloud.", "cell_type": "markdown", "metadata": {}}, {"source": "db2_service_credentials = {\n  \"port\": 50000,\n  \"db\": \"BLUDB\",\n  \"username\": \"***\",\n  \"ssljdbcurl\": \"***\",\n  \"host\": \"***\",\n  \"https_url\": \"***\",\n  \"dsn\": \"***\",\n  \"hostname\": \"***\",\n  \"jdbcurl\": \"***\",\n  \"ssldsn\": \"***\",\n  \"uri\": \"***\",\n  \"password\": \"***\"\n}\n\ntraining_data_reference = {\n \"name\": \"MortgageComplaints_training_reference\",\n \"connection\": db2_service_credentials,\n \"source\": {\n  \"tablename\": \"MORTGAGE_ISSUES_TRAINING\",\n  \"type\": \"dashdb\"\n }\n}", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 12}, {"source": "Define OUTPUT_DATA_SCHEMA for the model", "cell_type": "markdown", "metadata": {}}, {"source": "train_data_schema = mortgage_training_data.schema\nlabel_field = next(f for f in train_data_schema.fields if f.name == \"ISSUE\")\nlabel_field.metadata['values'] = label_stringIdx.labels", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 13}, {"source": "Set up modelling roles in OUTPUT_DATA_SCHEMA", "cell_type": "markdown", "metadata": {}}, {"source": "from pyspark.sql.types import *\n\ninput_fileds = filter(lambda f: f.name != \"ISSUE\", train_data_schema.fields)\n\noutput_data_schema = StructType(list(input_fileds)). \\\n    add(\"prediction\", DoubleType(), True, {'modeling_role': 'prediction'}). \\\n    add(\"predictedLabel\", StringType(), True, {'modeling_role': 'decoded-target', 'values': label_stringIdx.labels}). \\\n    add(\"probability\", ArrayType(DoubleType()), True, {'modeling_role': 'probability'})", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 14}, {"source": "import json\nprint(json.dumps(output_data_schema.jsonValue(),indent=3))", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "{\n   \"fields\": [\n      {\n         \"metadata\": {\n            \"columnInfo\": {\n               \"columnType\": 12,\n               \"columnLength\": 32592,\n               \"columnSigned\": false,\n               \"columnScale\": 0,\n               \"columnTypeName\": \"varchar\",\n               \"columnNullable\": true,\n               \"columnPrimaryKey\": false\n            }\n         },\n         \"type\": \"string\",\n         \"name\": \"CONSUMER_COMPLAINT_NARRATIVE\",\n         \"nullable\": true\n      },\n      {\n         \"metadata\": {\n            \"modeling_role\": \"prediction\"\n         },\n         \"type\": \"double\",\n         \"name\": \"prediction\",\n         \"nullable\": true\n      },\n      {\n         \"metadata\": {\n            \"modeling_role\": \"decoded-target\",\n            \"values\": [\n               \"Loan servicing payments escrow account\",\n               \"Loan modification collection foreclosure\",\n               \"Trouble during payment process\",\n               \"Struggling to pay mortgage\",\n               \"Application originator mortgage broker\",\n               \"Settlement process and costs\",\n               \"Closing on a mortgage\",\n               \"Credit decision Underwriting\"\n            ]\n         },\n         \"type\": \"string\",\n         \"name\": \"predictedLabel\",\n         \"nullable\": true\n      },\n      {\n         \"metadata\": {\n            \"modeling_role\": \"probability\"\n         },\n         \"type\": {\n            \"containsNull\": true,\n            \"elementType\": \"double\",\n            \"type\": \"array\"\n         },\n         \"name\": \"probability\",\n         \"nullable\": true\n      }\n   ],\n   \"type\": \"struct\"\n}\n"}], "execution_count": 15}, {"source": "Add all the information to model meta props.", "cell_type": "markdown", "metadata": {}}, {"source": "model_properties = {\n    client.repository.ModelMetaNames.NAME: \"Spark_Mortgage_Complaints\",\n    client.repository.ModelMetaNames.TRAINING_DATA_REFERENCE: training_data_reference,\n    client.repository.ModelMetaNames.EVALUATION_METHOD: \"multiclass\",\n    client.repository.ModelMetaNames.OUTPUT_DATA_SCHEMA: output_data_schema.jsonValue(),\n    client.repository.ModelMetaNames.EVALUATION_METRICS: [{\"name\": \"accuracy\", \"value\": accuracy, \"threshold\": 0.6}]\n}", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 17}, {"source": "Save the model.", "cell_type": "markdown", "metadata": {}}, {"source": "published_model_details = client.repository.store_model(model=NBmodel, meta_props=model_properties, training_data=mortgage_training_data, pipeline=SparkPipeline)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 18}, {"source": "List all Models in the repository", "cell_type": "markdown", "metadata": {}}, {"source": "model_uid = client.repository.get_model_uid(published_model_details)\nclient.repository.list_models()\nprint(model_uid)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "------------------------------------  ------------------------------------  ------------------------  --------------\nGUID                                  NAME                                  CREATED                   FRAMEWORK\n9f72ffe8-eafb-4f78-9453-b44f09a6860c  Spark_Mortgage_Complaints1            2018-11-26T16:28:24.194Z  mllib-2.1\nb93e16f7-882b-47d3-a7b3-7bd007654bd6  Spark_Mortgage_Complaints             2018-11-23T10:19:23.558Z  mllib-2.1\n44f31ee1-3888-47d6-afaf-1fae29293131  Keras Consumer Complaints K80         2018-11-15T15:44:47.410Z  tensorflow-1.5\neaadfeb9-5a95-4e92-8b47-0140b04102d8  MortgageComplaintsWithKerasAITest     2018-11-15T11:43:08.960Z  tensorflow-1.5\n03b44eb1-b159-4e74-a1b7-c073bf64f2ab  MNIST model                           2018-11-14T14:27:23.079Z  tensorflow-1.5\n6f104e6d-31d9-4edb-b07a-f0a15ebc86bf  CC_FUN                                2018-11-08T13:16:00.605Z  tensorflow-1.5\nd5960e54-ef94-4dd0-951e-c147db5f4907  CC_F                                  2018-11-08T11:16:20.914Z  tensorflow-1.5\nf1e56025-5b6f-4acb-a20f-fd6337315cba  CC3                                   2018-11-02T13:48:24.118Z  tensorflow-1.5\n9d10e6e5-a845-4598-8935-ae00ba5b6d03  CC2                                   2018-11-01T13:30:30.783Z  tensorflow-1.5\n701b9c9d-13df-4c27-8eff-f9bf2778deff  Customer Complaints Issue Classifier  2018-10-30T15:03:15.160Z  tensorflow-1.5\n------------------------------------  ------------------------------------  ------------------------  --------------\n9f72ffe8-eafb-4f78-9453-b44f09a6860c\n"}], "execution_count": 19}, {"source": "Get the model details of our current deployed model.", "cell_type": "markdown", "metadata": {}}, {"source": "model_details = client.repository.get_model_details(model_uid)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 20}, {"source": "<a id=\"score\"></a>\n## 4. Deploy and score", "cell_type": "markdown", "metadata": {}}, {"source": "Deploy previously stored model as web service.", "cell_type": "markdown", "metadata": {}}, {"source": "deployment_details = client.deployments.create(model_uid=model_uid, name='Spark_Mortgage_Complaints')", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "\n\n#######################################################################################\n\nSynchronous deployment creation for uid: '9f72ffe8-eafb-4f78-9453-b44f09a6860c' started\n\n#######################################################################################\n\n\nINITIALIZING\nDEPLOY_SUCCESS\n\n\n------------------------------------------------------------------------------------------------\nSuccessfully finished deployment creation, deployment_uid='910d5f62-77ec-40b6-8ea3-50a2919c5d51'\n------------------------------------------------------------------------------------------------\n\n\n"}], "execution_count": 21}, {"source": "Get the scoring endpoint.", "cell_type": "markdown", "metadata": {}}, {"source": "scoring_url = client.deployments.get_scoring_url(deployment_details)\nprint(scoring_url)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "https://us-south.ml.cloud.ibm.com/v3/wml_instances/34399854-47de-41c8-949e-267347c29223/deployments/910d5f62-77ec-40b6-8ea3-50a2919c5d51/online\n"}], "execution_count": 22}, {"source": "Test Recommended action from the model", "cell_type": "markdown", "metadata": {}}, {"source": "fields = ['CONSUMER_COMPLAINT_NARRATIVE']\nvalues = ['I have a loan in foreclosure with my Mortgage company, Loan # XXXX, and I re-applied for a loan modification on XXXX XXXX, 2016.']", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 23}, {"source": "payload_scoring = {\"fields\": fields,\"values\": [values]}\nscoring_response = client.deployments.score(scoring_url, payload_scoring)\n\nprint(\"Recommended action: \" + json.dumps(scoring_response['values'][0][7], indent=3))\n#print(json.dumps(scoring_response,indent=3))", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Recommended action: \"Loan modification collection foreclosure\"\n"}], "execution_count": 24}], "metadata": {"kernelspec": {"display_name": "Python 3.5 with Spark 2.1", "name": "python3-spark21", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.5.4", "name": "python", "pygments_lexer": "ipython3", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}}}, "nbformat": 4}